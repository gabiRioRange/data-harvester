ğŸšœ Data Harvester 3.0 (Firefox Edition)

Data Harvester Ã© uma ferramenta de engenharia de dados universal projetada para coletar, limpar e estruturar informaÃ§Ãµes da web de forma automÃ¡tica. Diferente de scrapers simples, ele utiliza um motor hÃ­brido (Requests para velocidade e Selenium/Firefox para sites dinÃ¢micos) e processamento paralelo para alta performance.
âœ¨ Funcionalidades Principais

    âš¡ Modo Turbo (Multithreading): Processa mÃºltiplos sites simultaneamente, reduzindo drasticamente o tempo de coleta.

    ğŸ¦Š HÃ­brido & DinÃ¢mico: Alterna entre Requests (leve) e Selenium GeckoDriver (para sites com JavaScript, React, Angular).

    ğŸ“Š ExtraÃ§Ã£o Inteligente: Identifica e estrutura automaticamente:

        TÃ­tulos (H1-H3)

        ParÃ¡grafos de conteÃºdo

        Links Ãºteis

        Tabelas HTML (converte automaticamente para abas no Excel)

        Metadados (SEO descriptions, keywords)

    ğŸ›¡ï¸ ResiliÃªncia: Sistema de Retry automÃ¡tico para falhas de conexÃ£o e rotaÃ§Ã£o de User-Agent para evitar bloqueios.

    ğŸ“‘ SaÃ­da Organizada: Gera arquivos JSON (dados brutos) e Excel (.xlsx) com abas separadas para cada tipo de dado.

    ğŸ“ Logs Profissionais: Rastreabilidade completa via arquivo execution.log.

ğŸ› ï¸ InstalaÃ§Ã£o
PrÃ©-requisitos

    Python 3.8+ instalado.

    Mozilla Firefox instalado na mÃ¡quina (para o modo dinÃ¢mico).

Passo a Passo

    Clone o repositÃ³rio:
    Bash

git clone https://github.com/gabiRioRange/data-harvester.git
cd data-harvester

Crie e ative um ambiente virtual (recomendado):
Bash

python -m venv .venv
# Windows:
.venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate

Instale as dependÃªncias:
Bash

    pip install requests beautifulsoup4 pandas lxml openpyxl selenium webdriver-manager fake-useragent

ğŸš€ Como Usar

Execute o script principal:
Bash

python harvester.py

VocÃª verÃ¡ um menu interativo:
OpÃ§Ã£o 1: Teste Ãšnico

Ideal para testar uma URL especÃ­fica rapidamente. O script perguntarÃ¡ a URL e salvarÃ¡ os dados.
OpÃ§Ã£o 2: Processamento em Lote (Turbo)

LÃª um arquivo de texto com mÃºltiplas URLs e processa todas em paralelo.

    Crie um arquivo chamado urls.txt na pasta do projeto.

    Adicione um link por linha:
    Plaintext

    https://www.python.org
    https://news.ycombinator.com
    https://exemplo.com/dados-financeiros

    Escolha a OpÃ§Ã£o 2 no menu.

    Defina se deseja usar o Firefox (Modo DinÃ¢mico) ou Requests (Modo RÃ¡pido).

ğŸ“‚ Estrutura do Projeto
Plaintext

data-harvester/
â”‚
â”œâ”€â”€ exports/               # ğŸ“‚ Onde os dados (JSON/Excel) sÃ£o salvos automaticamente
â”‚   â”œâ”€â”€ python_org_20231208.xlsx
â”‚   â””â”€â”€ python_org_20231208.json
â”‚
â”œâ”€â”€ harvester.py           # ğŸ§  O cÃ©rebro do scraper (Script Principal)
â”œâ”€â”€ urls.txt               # ğŸ“„ Lista de sites para processamento em lote
â”œâ”€â”€ execution.log          # ğŸ“ HistÃ³rico de erros e sucessos
â””â”€â”€ README.md              # ğŸ“„ DocumentaÃ§Ã£o

ğŸ’¾ Exemplo de SaÃ­da (Excel)

O arquivo Excel gerado Ã© altamente organizado:
Aba	ConteÃºdo
Metadata	TÃ­tulo da pÃ¡gina, URL, Data da coleta, Description.
Links	Lista de todos os links encontrados e seus textos.
Conteudo_Texto	Todos os cabeÃ§alhos e parÃ¡grafos em ordem de leitura.
Tabela_0, Tabela_1...	Cada tabela HTML encontrada vira uma aba separada e limpa.
ğŸ‘¤ Autor

Gabriel - Desenvolvedor Python | Backend & AutomaÃ§Ã£o